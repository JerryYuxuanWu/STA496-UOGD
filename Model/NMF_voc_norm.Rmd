---
title: "NMF"
author: "William Zhang"
date: "2023-11-19"
output: html_document
---
```{r}
# load the packages
library(NMF)
library(dplyr)
```

## Reading the data
```{r}
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
```
```{r}
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()

# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))

# retrieving the non-vocs: co2_ppm, nox, ch4, h2s, so2, o3
hourly_non_vocs <- hourly_radon_nona %>% select(c(co2_ppm, nox, o3, h2s, so2, ch4))
```
### VOC preprocessing
```{r}
# find the min for background-levels
background_levels <- sapply(hourly_vocs, min)
```
```{r}
background_levels
```
```{r}
#adjusting by subtracting the minimum value
adjusted_hourly_vocs <- as.data.frame(sapply(names(hourly_vocs), function(tracer){ 
  hourly_vocs[[tracer]] - background_levels[[tracer]]
}))
```

```{r}
# simply checking how many minimum values for each vocs
colSums(adjusted_hourly_vocs == 0)
```
```{r}
#adjustments that were made according to paper
#William: I'm guessing this refers to Gunnar's paper section 2.2
adjusting_negligible_background_from_LOD <- function(data_frame, LOD){ 
  adjusted <- data_frame
  for (x in names(data_frame)){
    
    min_value <- min(data_frame[x], na.rm = TRUE)
    max_value <- max(data_frame[x], na.rm = TRUE)
    if (min_value < 2 * LOD || max_value > 100 * LOD ){
      adjusted[[x]] <- -100
    }
  }
  return (adjusted)
}
```

```{r}
# split the VOCs based on their LOD levels, take out the different ones
# ethane, propane, benzene, acetylene
ethane_col <- adjusted_hourly_vocs %>% select(ethane)
propane_col <- adjusted_hourly_vocs %>% select(propane)
benzene_col <- adjusted_hourly_vocs %>% select(benzene)
acetylene_col <- adjusted_hourly_vocs %>% select(acetylene)
rest_col <- adjusted_hourly_vocs %>% select(-ethane, -propane, -benzene, -acetylene)
```
```{r}
# make the adjustments
ethane <- adjusting_negligible_background_from_LOD(ethane_col, 0.1)
propane <- adjusting_negligible_background_from_LOD(propane_col, 0.05)
benzene <- adjusting_negligible_background_from_LOD(benzene_col, 0.005)
acetylene <- adjusting_negligible_background_from_LOD(acetylene_col, 0.01)
rest <- adjusting_negligible_background_from_LOD(rest_col, 0.01)
```
```{r}
# checking how many are negative
colSums(rest < 0)
```

```{r}
# replace negative values with random values between 0 and 0.5*LOD
replace_negatives_with_random <- function(data_frame, LOD){
  adjusted <- data_frame
  for (x in names(data_frame)){
    negatives_exist <- any(data_frame[[x]] < 0, na.rm = TRUE)
    if (negatives_exist){
      adjusted[[x]] <- runif(nrow(data_frame), 0, 0.5 * LOD)
    }
  }
  return (adjusted)
}
```
```{r}
ethane <- replace_negatives_with_random(ethane, 0.1)
propane <- replace_negatives_with_random(propane, 0.05)
benzene <- replace_negatives_with_random(benzene, 0.005)
acetylene <- replace_negatives_with_random(acetylene, 0.01)
rest <- replace_negatives_with_random(rest, 0.01)
```
```{r}
# Merging
Merged_VOCs <- cbind(ethane, propane, benzene, acetylene, rest)
```

### Normalize the non-vocs
```{r}
#normalizing function
normalize_column <- function(column){
  background <- quantile(column, 0)
  max <- quantile(column, 0.99)
  return ((column - background)/(max - background))
}
```
```{r}
#Getting the Transpose
Normalized_Data <- hourly_non_vocs 
Normalized_Data <- sapply(hourly_non_vocs, normalize_column) #normalize the NON_VOC
```
```{r}
# normalizing the vocs too
Normalized_VOCs <- sapply(Merged_VOCs, normalize_column)
```

### Combine and Transpose
```{r}
Transpose <- cbind(Normalized_Data, Normalized_VOCs) #important: using the normalized VOCs for this file

# Transpose <- cbind(Normalized_Data, Merged_VOCs)
# rownames(Transpose) <- as.character(Transpose[,1]) # I'm not able to run this line, but it shouldn't affect anything
Transpose_Matrix <- t(as.matrix(Transpose))

number_row<- dim(Transpose_Matrix)[1] #store number of rows (used for checking)
number_column<- dim(Transpose_Matrix)[2] #store number of columns
```

## NMF section
```{r}
n_rows <- nrow(Transpose_Matrix)
n_cols <- ncol(Transpose_Matrix)
weight_matrix <- matrix(0, nrow(Transpose_Matrix), ncol(Transpose_Matrix))
LOD_vector = c(0.05, 0.05, 1, 0.1, 0.1, 0.05, 0.1, 0.05, 0.005, 0.01) # hard-coded values for LOD_vector
# the orders are the same as the orders for the rows in Transpose_matrix; co2_ppm, nox, o3, h2s, ....

Rest = rep(0.01, 16) # rest of the VOCs are 0.01
LOD_vector_merged = c(LOD_vector, Rest) #merged the two results above
```


```{r}
# Based on the Guha paper
# next comment is from the other nmf R file

# creating uncertainty Matrix ???
for (i in 1:n_rows) { 
  for (j in 1:n_cols) {
    xij <- Transpose_Matrix[i, j]
    LOD <- LOD_vector_merged[i]  # Get LOD value for this row 
    if (i == 6){ # based on equation 6, we sqrt ch4 (at row = 6) and times by 1
      weight_matrix[i, j] <- sqrt(xij)
    }
    # row 1 and times 0.25 for co2 
    if (i == 1){
      weight_matrix[i, j] <- 0.25 * sqrt(xij)
    }
    else if (xij <= LOD) {
      weight_matrix[i, j] <- 2 * LOD # equation 5a) in reference paper
    } else {
      weight_matrix[i, j] <- sqrt(((0.1 * xij)**2 + LOD**2))  #equation 5c) in reference paper
    }
  }
}
```

```{r}
# set a seed for nmf
set.seed(123)
```

```{r}
#function below used to estimate the optimal rank and will be used in the nmf() function. 
# takes around 20-30 mins to run
estimate_rank <- nmfEstimateRank(Transpose_Matrix, 4:20, method = "ls-nmf", weight = weight_matrix, 5)
# changing the range of rank to 2:20 from 4:20
# nrun = 5

measures <- estimate_rank$measures
fit <- estimate_rank$fit
consensus <- estimate_rank$consensus
```
```{r}
# plots the NMF rank survey
plot(estimate_rank)
```


```{r}
# fitting the optimal rank based on the above plots
# the choice of the optimal rank needs to be discussed
output <- nmf(Transpose_Matrix, rank = 8, weight = weight_matrix, method = "ls-nmf")
W <- basis(output)
H <- coef(output)
```

### Source contributions
```{r}
# Plot source contributions for the first basis vector
barplot(W[, 1], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 1", las = 2)
```
```{r}
barplot(W[, 2], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 2", las=2)
```

```{r}
barplot(W[, 3], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 3", las=2)
```
```{r}
barplot(W[, 4], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 4", las=2)
```
```{r}
barplot(W[, 5], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 5", las=2)
```
```{r}
barplot(W[, 6], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 6", las=2)
```
```{r}
barplot(W[, 7], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 7", las=2)
```
```{r}
barplot(W[, 8], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 8", las=2)
```


