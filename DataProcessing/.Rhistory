library(lmtest)
library(vip)
library(car)
library(mgcv)
library(corrplot)
library(leaps)
library(gam)
loving_daily <- readRDS("../DataProcessing/Trailer_daily_merge.rds")
loving_hourly <- readRDS("../DataProcessing/Trailer_hourly_merge.rds")
# making NA count to 0
loving_daily$count[is.na(loving_daily$count)] <- 0
loving_hourly$count[is.na(loving_hourly$count)] <- 0
loving_daily$weighted.count[is.na(loving_daily$weighted.count)] <- 0
loving_hourly$weighted.count[is.na(loving_hourly$weighted.count)] <- 0
# none flare within 100km
loving_daily$closest.flare[is.na(loving_daily$closest.flare)] <- 100
loving_hourly$closest.flare[is.na(loving_hourly$closest.flare)] <- 100
# creating a dataframe without the flares data
loving_daily_noflares <- loving_daily %>% select(-c(temp_bb,rhi, esf_bb, distToLovi,inv_dist))
loving_hourly_noflares <- loving_hourly %>% select(-c(temp_bb,rhi, esf_bb, distToLovi,inv_dist))
loving_daily_noflares <- loving_daily_noflares %>% drop_na(toluene_mean, n.octane_mean)
loving_hourly_noflares <- loving_hourly_noflares %>% drop_na(toluene, n.octane)
# save the datasets to rds for other file to use
saveRDS(loving_daily_noflares, "daily_radon.rds")
saveRDS(loving_hourly_noflares, "hourly_radon.rds")
# Helper Function to find top 5 correlated variables
top_correlated <- function(cor_matrix, var_name, top_n = 5) {
# Get the absolute values of correlations for the variable
cor_values <- abs(cor_matrix[var_name, ])
# Exclude the variable itself from consideration
cor_values[var_name] <- 0
# Find the top n correlated variables
top_cor <- sort(cor_values, decreasing = TRUE)[1:top_n]
# Get the names of the top correlated variables
top_cor_names <- names(top_cor)
# Get the correlation scores
top_cor_scores <- cor_matrix[var_name, top_cor_names]
return (list(variables = top_cor_names, scores = top_cor_scores))
}
cor_matrix = cor(loving_daily_noflares %>% select(-c("radon_B_mean", "rd_particle_B_mean", "datetime", "monthly_oil", "monthly_gas", "distToLovi_wells", "isoprene_mean", "m.p.xylene_mean", "ethyl.benzene_mean")) %>% na.omit())
corrplot.mixed(cor_matrix, number.cex = 0.4, tl.pos = 'lt', order = 'original')
knitr::opts_chunk$set(warning=FALSE)
loving_daily <- readRDS("../DataProcessing/Trailer_daily_merge.rds")
loving_hourly <- readRDS("../DataProcessing/Trailer_hourly_merge.rds")
# making NA count to 0
loving_daily$count[is.na(loving_daily$count)] <- 0
loving_hourly$count[is.na(loving_hourly$count)] <- 0
loving_daily$weighted.count[is.na(loving_daily$weighted.count)] <- 0
loving_hourly$weighted.count[is.na(loving_hourly$weighted.count)] <- 0
# none flare within 100km
loving_daily$closest.flare[is.na(loving_daily$closest.flare)] <- 100
loving_hourly$closest.flare[is.na(loving_hourly$closest.flare)] <- 100
# creating a dataframe without the flares data
loving_daily_noflares <- loving_daily %>% select(-c(temp_bb,rhi, esf_bb, distToLovi,inv_dist))
loving_hourly_noflares <- loving_hourly %>% select(-c(temp_bb,rhi, esf_bb, distToLovi,inv_dist))
loving_daily_noflares <- loving_daily_noflares %>% drop_na(toluene_mean, n.octane_mean)
loving_hourly_noflares <- loving_hourly_noflares %>% drop_na(toluene, n.octane)
# save the datasets to rds for other file to use
saveRDS(loving_daily_noflares, "daily_rd.rds")
saveRDS(loving_hourly_noflares, "hourly_rd.rds")
# load the packages
library(NMF)
library(dplyr)
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()
# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))
# retrieving the non-vocs: co2_ppm, nox, ch4, h2s, so2, o3
hourly_non_vocs <- hourly_radon_nona %>% select(c(co2_ppm, nox, o3, h2s, so2, ch4))
# find the min for background-levels
background_levels <- sapply(hourly_vocs, min)
background_levels
#adjusting by subtracting the minimum value
adjusted_hourly_vocs <- as.data.frame(sapply(names(hourly_vocs), function(tracer){
hourly_vocs[[tracer]] - background_levels[[tracer]]
}))
# simply checking how many minimum values for each vocs
colSums(adjusted_hourly_vocs == 0)
#adjustments that were made according to paper
#William: I'm guessing this refers to Gunnar's paper section 2.2
adjusting_negligible_background_from_LOD <- function(data_frame, LOD){
adjusted <- data_frame
for (x in names(data_frame)){
min_value <- min(data_frame[x], na.rm = TRUE)
max_value <- max(data_frame[x], na.rm = TRUE)
if (min_value < 2 * LOD || max_value > 100 * LOD ){
adjusted[[x]] <- -100
}
}
return (adjusted)
}
# split the VOCs based on their LOD levels, take out the different ones
# ethane, propane, benzene, acetylene
ethane_col <- adjusted_hourly_vocs %>% select(ethane)
propane_col <- adjusted_hourly_vocs %>% select(propane)
benzene_col <- adjusted_hourly_vocs %>% select(benzene)
acetylene_col <- adjusted_hourly_vocs %>% select(acetylene)
rest_col <- adjusted_hourly_vocs %>% select(-ethane, -propane, -benzene, -acetylene)
# make the adjustments
ethane <- adjusting_negligible_background_from_LOD(ethane_col, 0.1)
propane <- adjusting_negligible_background_from_LOD(propane_col, 0.05)
benzene <- adjusting_negligible_background_from_LOD(benzene_col, 0.005)
acetylene <- adjusting_negligible_background_from_LOD(acetylene_col, 0.01)
rest <- adjusting_negligible_background_from_LOD(rest_col, 0.01)
# checking how many are negative
colSums(rest < 0)
# replace negative values with random values between 0 and 0.5*LOD
replace_negatives_with_random <- function(data_frame, LOD){
adjusted <- data_frame
for (x in names(data_frame)){
negatives_exist <- any(data_frame[[x]] < 0, na.rm = TRUE)
if (negatives_exist){
adjusted[[x]] <- runif(nrow(data_frame), 0, 0.5 * LOD)
}
}
return (adjusted)
}
ethane <- replace_negatives_with_random(ethane, 0.1)
propane <- replace_negatives_with_random(propane, 0.05)
benzene <- replace_negatives_with_random(benzene, 0.005)
acetylene <- replace_negatives_with_random(acetylene, 0.01)
rest <- replace_negatives_with_random(rest, 0.01)
# Merging
Merged_VOCs <- cbind(ethane, propane, benzene, acetylene, rest)
#normalizing function
normalize_column <- function(column){
background <- quantile(column, 0)
max <- quantile(column, 0.99)
return ((column - background)/(max - background))
}
#Getting the Transpose
Normalized_Data <- hourly_non_vocs
Normalized_Data <- sapply(hourly_non_vocs, normalize_column) #normalize the NON_VOC
# normalizing the vocs too
Normalized_VOCs <- sapply(Merged_VOCs, normalize_column)
# Transpose <- cbind(Normalized_Data, Normalized_VOCs) #combine the non-VOC and normalized VOC
Transpose <- cbind(Normalized_Data, Merged_VOCs) # IMPORTANT: using the un-normalized VOCs for this file
# rownames(Transpose) <- as.character(Transpose[,1]) # I'm not able to run this line, but it shouldn't affect anything
Transpose_Matrix <- t(as.matrix(Transpose))
number_row<- dim(Transpose_Matrix)[1] #store number of rows (used for checking)
number_column<- dim(Transpose_Matrix)[2] #store number of columns
n_rows <- nrow(Transpose_Matrix)
n_cols <- ncol(Transpose_Matrix)
weight_matrix <- matrix(0, nrow(Transpose_Matrix), ncol(Transpose_Matrix))
LOD_vector = c(0.05, 0.05, 1, 0.1, 0.1, 0.05, 0.1, 0.05, 0.005, 0.01) # hard-coded values for LOD_vector
# the orders are the same as the orders for the rows in Transpose_matrix; co2_ppm, nox, o3, h2s, ....
Rest = rep(0.01, 16) # rest of the VOCs are 0.01
LOD_vector_merged = c(LOD_vector, Rest) #merged the two results above
# Based on the Guha paper
# next comment is from the other nmf R file
# creating uncertainty Matrix ???
for (i in 1:n_rows) {
for (j in 1:n_cols) {
xij <- Transpose_Matrix[i, j]
LOD <- LOD_vector_merged[i]  # Get LOD value for this row
if (i == 6){ # based on equation 6, we sqrt ch4 (at row = 6) and times by 1
weight_matrix[i, j] <- sqrt(xij)
}
# row 1 and times 0.25 for co2
if (i == 1){
weight_matrix[i, j] <- 0.25 * sqrt(xij)
}
else if (xij <= LOD) {
weight_matrix[i, j] <- 2 * LOD # equation 5a) in reference paper
} else {
weight_matrix[i, j] <- sqrt(((0.1 * xij)**2 + LOD**2))  #equation 5c) in reference paper
}
}
}
Transpose_Matrix
n_rows
n_cols
Transpose
Normalized_Data
Merged_VOCs
hourly_non_vocs
normalize_column
# load the packages
library(NMF)
library(dplyr)
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()
# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))
# retrieving the non-vocs: co2_ppm, nox, ch4, h2s, so2, o3
hourly_non_vocs <- hourly_radon_nona %>% select(c(co2_ppm, nox, o3, h2s, so2, ch4))
View(hourly_vocs)
View(hourly_radon)
# ignore bc for now
hourly_radon <- hourly_radon %>% select(-bc)
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()
# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))
# retrieving the non-vocs: co2_ppm, nox, ch4, h2s, so2, o3
hourly_non_vocs <- hourly_radon_nona %>% select(c(co2_ppm, nox, o3, h2s, so2, ch4))
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
# ignore bc for now
hourly_radon <- hourly_radon %>% select(-bc)
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()
# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))
# retrieving the non-vocs: co2_ppm, nox, ch4, h2s, so2, o3
hourly_non_vocs <- hourly_radon_nona %>% select(c(co2_ppm, nox, o3, h2s, so2, ch4))
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag))
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag))
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()
# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))
# retrieving the non-vocs: co2_ppm, nox, ch4, h2s, so2, o3
hourly_non_vocs <- hourly_radon_nona %>% select(c(co2_ppm, nox, o3, h2s, so2, ch4))
# find the min for background-levels
background_levels <- sapply(hourly_vocs, min)
background_levels
#adjusting by subtracting the minimum value
adjusted_hourly_vocs <- as.data.frame(sapply(names(hourly_vocs), function(tracer){
hourly_vocs[[tracer]] - background_levels[[tracer]]
}))
# simply checking how many minimum values for each vocs
colSums(adjusted_hourly_vocs == 0)
#adjustments that were made according to paper
#William: I'm guessing this refers to Gunnar's paper section 2.2
adjusting_negligible_background_from_LOD <- function(data_frame, LOD){
adjusted <- data_frame
for (x in names(data_frame)){
min_value <- min(data_frame[x], na.rm = TRUE)
max_value <- max(data_frame[x], na.rm = TRUE)
if (min_value < 2 * LOD || max_value > 100 * LOD ){
adjusted[[x]] <- -100
}
}
return (adjusted)
}
# split the VOCs based on their LOD levels, take out the different ones
# ethane, propane, benzene, acetylene
ethane_col <- adjusted_hourly_vocs %>% select(ethane)
propane_col <- adjusted_hourly_vocs %>% select(propane)
benzene_col <- adjusted_hourly_vocs %>% select(benzene)
acetylene_col <- adjusted_hourly_vocs %>% select(acetylene)
rest_col <- adjusted_hourly_vocs %>% select(-ethane, -propane, -benzene, -acetylene)
# make the adjustments
ethane <- adjusting_negligible_background_from_LOD(ethane_col, 0.1)
propane <- adjusting_negligible_background_from_LOD(propane_col, 0.05)
benzene <- adjusting_negligible_background_from_LOD(benzene_col, 0.005)
acetylene <- adjusting_negligible_background_from_LOD(acetylene_col, 0.01)
rest <- adjusting_negligible_background_from_LOD(rest_col, 0.01)
# checking how many are negative
colSums(rest < 0)
# replace negative values with random values between 0 and 0.5*LOD
replace_negatives_with_random <- function(data_frame, LOD){
adjusted <- data_frame
for (x in names(data_frame)){
negatives_exist <- any(data_frame[[x]] < 0, na.rm = TRUE)
if (negatives_exist){
adjusted[[x]] <- runif(nrow(data_frame), 0, 0.5 * LOD)
}
}
return (adjusted)
}
ethane <- replace_negatives_with_random(ethane, 0.1)
propane <- replace_negatives_with_random(propane, 0.05)
benzene <- replace_negatives_with_random(benzene, 0.005)
acetylene <- replace_negatives_with_random(acetylene, 0.01)
rest <- replace_negatives_with_random(rest, 0.01)
# Merging
Merged_VOCs <- cbind(ethane, propane, benzene, acetylene, rest)
#normalizing function
normalize_column <- function(column){
background <- quantile(column, 0)
max <- quantile(column, 0.99)
return ((column - background)/(max - background))
}
#Getting the Transpose
Normalized_Data <- hourly_non_vocs
Normalized_Data <- sapply(hourly_non_vocs, normalize_column) #normalize the NON_VOC
# normalizing the vocs too
Normalized_VOCs <- sapply(Merged_VOCs, normalize_column)
# Transpose <- cbind(Normalized_Data, Normalized_VOCs) #combine the non-VOC and normalized VOC
Transpose <- cbind(Normalized_Data, Merged_VOCs) # IMPORTANT: using the un-normalized VOCs for this file
# rownames(Transpose) <- as.character(Transpose[,1]) # I'm not able to run this line, but it shouldn't affect anything
Transpose_Matrix <- t(as.matrix(Transpose))
number_row<- dim(Transpose_Matrix)[1] #store number of rows (used for checking)
number_column<- dim(Transpose_Matrix)[2] #store number of columns
n_rows <- nrow(Transpose_Matrix)
n_cols <- ncol(Transpose_Matrix)
weight_matrix <- matrix(0, nrow(Transpose_Matrix), ncol(Transpose_Matrix))
LOD_vector = c(0.05, 0.05, 1, 0.1, 0.1, 0.05, 0.1, 0.05, 0.005, 0.01) # hard-coded values for LOD_vector
# the orders are the same as the orders for the rows in Transpose_matrix; co2_ppm, nox, o3, h2s, ....
Rest = rep(0.01, 16) # rest of the VOCs are 0.01
LOD_vector_merged = c(LOD_vector, Rest) #merged the two results above
# Based on the Guha paper
# next comment is from the other nmf R file
# creating uncertainty Matrix ???
for (i in 1:n_rows) {
for (j in 1:n_cols) {
xij <- Transpose_Matrix[i, j]
LOD <- LOD_vector_merged[i]  # Get LOD value for this row
if (i == 6){ # based on equation 6, we sqrt ch4 (at row = 6) and times by 1
weight_matrix[i, j] <- sqrt(xij)
}
# row 1 and times 0.25 for co2
if (i == 1){
weight_matrix[i, j] <- 0.25 * sqrt(xij)
}
else if (xij <= LOD) {
weight_matrix[i, j] <- 2 * LOD # equation 5a) in reference paper
} else {
weight_matrix[i, j] <- sqrt(((0.1 * xij)**2 + LOD**2))  #equation 5c) in reference paper
}
}
}
LOD
LOD_vector_merged
i
length(LOD_vector_merged)
Transpose_Matrix
View(Transpose_Matrix)
n_rows
# read the radon data
hourly_radon <- readRDS("hourly_radon_old.rds")
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
hourly_radon_old <- readRDS("hourly_radon_old.rds")
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag))
View(hourly_radon_old)
names(hourly_radon)
names(hourly_radon_old)
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag, intensity_a, intensity_b, instr_temp_c, lamp_temp_c, flow_a, flow_b, pressure.x, pressure.y)) %>%
relocate(pressure_altcorr, after = temp_f)
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
hourly_radon_old <- readRDS("hourly_radon_old.rds")
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag, intensity_a, intensity_b, instr_temp_c, lamp_temp_c, flow_a, flow_b, pressure.x, pressure.y)) %>%
relocate(pressure_altcorr, after = temp_f)
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()
# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))
names(hourly_radon)
?relocate
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag, intensity_a, intensity_b, instr_temp_c, lamp_temp_c, flow_a, flow_b, pressure.x, pressure.y)) %>%
relocate(pressure_altcorr, .after = temp_f)
names(hourly_radon)
names(hourly_radon_old)
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
hourly_radon_old <- readRDS("hourly_radon_old.rds")
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag, intensity_a, intensity_b, instr_temp_c, lamp_temp_c, flow_a, flow_b, pressure.x, pressure.y, mode, water_vapor_mr, T101_mode)) %>%
relocate(pressure_altcorr, .after = temp_f)
# read the radon data
hourly_radon <- readRDS("hourly_radon.rds")
hourly_radon_old <- readRDS("hourly_radon_old.rds")
# ignore bc and flag for o3 for now
hourly_radon <- hourly_radon %>% select(-c(bc, flag, intensity_a, intensity_b, instr_temp_c, lamp_temp_c, flow_a, flow_b, pressure.x, pressure.y, mode, water_vapor_mr, T101_Mode)) %>%
relocate(pressure_altcorr, .after = temp_f)
# remove NAs
hourly_radon_nona <- hourly_radon %>% select(-c(distToLovi_wells, monthly_oil, monthly_gas)) %>% na.omit()
# retrieving the vocs, removing everything else except the vocs
hourly_vocs <- hourly_radon_nona %>% select(-c(datetime, time_hourly, radon_B, radon_pCi, rd_particle_B, rd_particle_pCi, co, co2_ppm, no, no2, nox, o3, h2s, so2, ch4, temp_f, pressure_altcorr, rain, relh, wsp, wdr, solr, co2_ppm, hour, closest.flare, count, weighted.count))
# retrieving the non-vocs: co2_ppm, nox, ch4, h2s, so2, o3
hourly_non_vocs <- hourly_radon_nona %>% select(c(co2_ppm, nox, o3, h2s, so2, ch4))
names(hourly_radon)
names(hourly_radon_old)
names(hourly_radon) == names(hourly_radon_old)
# find the min for background-levels
background_levels <- sapply(hourly_vocs, min)
background_levels
#adjusting by subtracting the minimum value
adjusted_hourly_vocs <- as.data.frame(sapply(names(hourly_vocs), function(tracer){
hourly_vocs[[tracer]] - background_levels[[tracer]]
}))
# simply checking how many minimum values for each vocs
colSums(adjusted_hourly_vocs == 0)
#adjustments that were made according to paper
#William: I'm guessing this refers to Gunnar's paper section 2.2
adjusting_negligible_background_from_LOD <- function(data_frame, LOD){
adjusted <- data_frame
for (x in names(data_frame)){
min_value <- min(data_frame[x], na.rm = TRUE)
max_value <- max(data_frame[x], na.rm = TRUE)
if (min_value < 2 * LOD || max_value > 100 * LOD ){
adjusted[[x]] <- -100
}
}
return (adjusted)
}
# split the VOCs based on their LOD levels, take out the different ones
# ethane, propane, benzene, acetylene
ethane_col <- adjusted_hourly_vocs %>% select(ethane)
propane_col <- adjusted_hourly_vocs %>% select(propane)
benzene_col <- adjusted_hourly_vocs %>% select(benzene)
acetylene_col <- adjusted_hourly_vocs %>% select(acetylene)
rest_col <- adjusted_hourly_vocs %>% select(-ethane, -propane, -benzene, -acetylene)
# make the adjustments
ethane <- adjusting_negligible_background_from_LOD(ethane_col, 0.1)
propane <- adjusting_negligible_background_from_LOD(propane_col, 0.05)
benzene <- adjusting_negligible_background_from_LOD(benzene_col, 0.005)
acetylene <- adjusting_negligible_background_from_LOD(acetylene_col, 0.01)
rest <- adjusting_negligible_background_from_LOD(rest_col, 0.01)
# checking how many are negative
colSums(rest < 0)
# replace negative values with random values between 0 and 0.5*LOD
replace_negatives_with_random <- function(data_frame, LOD){
adjusted <- data_frame
for (x in names(data_frame)){
negatives_exist <- any(data_frame[[x]] < 0, na.rm = TRUE)
if (negatives_exist){
adjusted[[x]] <- runif(nrow(data_frame), 0, 0.5 * LOD)
}
}
return (adjusted)
}
ethane <- replace_negatives_with_random(ethane, 0.1)
propane <- replace_negatives_with_random(propane, 0.05)
benzene <- replace_negatives_with_random(benzene, 0.005)
acetylene <- replace_negatives_with_random(acetylene, 0.01)
rest <- replace_negatives_with_random(rest, 0.01)
# Merging
Merged_VOCs <- cbind(ethane, propane, benzene, acetylene, rest)
#normalizing function
normalize_column <- function(column){
background <- quantile(column, 0)
max <- quantile(column, 0.99)
return ((column - background)/(max - background))
}
#Getting the Transpose
Normalized_Data <- hourly_non_vocs
Normalized_Data <- sapply(hourly_non_vocs, normalize_column) #normalize the NON_VOC
# normalizing the vocs too
Normalized_VOCs <- sapply(Merged_VOCs, normalize_column)
# Transpose <- cbind(Normalized_Data, Normalized_VOCs) #combine the non-VOC and normalized VOC
Transpose <- cbind(Normalized_Data, Merged_VOCs) # IMPORTANT: using the un-normalized VOCs for this file
# rownames(Transpose) <- as.character(Transpose[,1]) # I'm not able to run this line, but it shouldn't affect anything
Transpose_Matrix <- t(as.matrix(Transpose))
number_row<- dim(Transpose_Matrix)[1] #store number of rows (used for checking)
number_column<- dim(Transpose_Matrix)[2] #store number of columns
n_rows <- nrow(Transpose_Matrix)
n_cols <- ncol(Transpose_Matrix)
weight_matrix <- matrix(0, nrow(Transpose_Matrix), ncol(Transpose_Matrix))
LOD_vector = c(0.05, 0.05, 1, 0.1, 0.1, 0.05, 0.1, 0.05, 0.005, 0.01) # hard-coded values for LOD_vector
# the orders are the same as the orders for the rows in Transpose_matrix; co2_ppm, nox, o3, h2s, ....
Rest = rep(0.01, 16) # rest of the VOCs are 0.01
LOD_vector_merged = c(LOD_vector, Rest) #merged the two results above
# Based on the Guha paper
# next comment is from the other nmf R file
# creating uncertainty Matrix ???
for (i in 1:n_rows) {
for (j in 1:n_cols) {
xij <- Transpose_Matrix[i, j]
LOD <- LOD_vector_merged[i]  # Get LOD value for this row
if (i == 6){ # based on equation 6, we sqrt ch4 (at row = 6) and times by 1
weight_matrix[i, j] <- sqrt(xij)
}
# row 1 and times 0.25 for co2
if (i == 1){
weight_matrix[i, j] <- 0.25 * sqrt(xij)
}
else if (xij <= LOD) {
weight_matrix[i, j] <- 2 * LOD # equation 5a) in reference paper
} else {
weight_matrix[i, j] <- sqrt(((0.1 * xij)**2 + LOD**2))  #equation 5c) in reference paper
}
}
}
# set a seed for nmf
set.seed(123)
#function below used to estimate the optimal rank and will be used in the nmf() function.
# takes around 20-30 mins to run
estimate_rank <- nmfEstimateRank(Transpose_Matrix, 4:20, method = "ls-nmf", weight = weight_matrix, 5)
# changing the range of rank to 2:20 from 4:20
# nrun = 5
measures <- estimate_rank$measures
fit <- estimate_rank$fit
consensus <- estimate_rank$consensus
# plots the NMF rank survey
plot(estimate_rank)
# fitting the optimal rank based on the above plots
# the choice of the optimal rank needs to be discussed
output <- nmf(Transpose_Matrix, rank = 8, weight = weight_matrix, method = "ls-nmf")
W <- basis(output)
H <- coef(output)
# Plot source contributions for the first basis vector
barplot(W[, 1], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 1", las = 2)
barplot(W[, 2], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 2", las=2)
barplot(W[, 3], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 3", las=2)
barplot(W[, 4], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 4", las=2)
barplot(W[, 5], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 5", las=2)
barplot(W[, 6], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 6", las=2)
barplot(W[, 7], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 7", las=2)
barplot(W[, 8], names.arg = rownames(Transpose_Matrix), main = "Source Contributions to Basis 8", las=2)
# changing the range of rank to 2:20 from 4:20
# nrun = 5
saveRDS(estimate_rank, 'estimate_rank.rds')
install.packages(c("backports", "fastmap", "ggplot2", "ggsci", "highr", "htmltools", "mvtnorm", "quantreg", "sp", "stringi", "terra", "textshaping", "urca", "xfun"))
